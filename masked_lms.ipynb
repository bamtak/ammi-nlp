{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "masked_lms.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2883f074d8f644b6896ea097eddecc1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c1614d1f2fd640bb9bfd84b5e58dd4aa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b978c117f5474998b517bc0605e8c4a4",
              "IPY_MODEL_d19f98724b394acc8e7f56b21a06b5b0"
            ]
          }
        },
        "c1614d1f2fd640bb9bfd84b5e58dd4aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b978c117f5474998b517bc0605e8c4a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5482db849f044ac9945aafe07463db67",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10bcd50c36cf4d9899354a042cab0148"
          }
        },
        "d19f98724b394acc8e7f56b21a06b5b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_596e239b10ec42168ceb0c72a52762ba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 213k/213k [00:00&lt;00:00, 2.44MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a8dfbc4f1e24400a2bc01d2bbfdcd12"
          }
        },
        "5482db849f044ac9945aafe07463db67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10bcd50c36cf4d9899354a042cab0148": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "596e239b10ec42168ceb0c72a52762ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a8dfbc4f1e24400a2bc01d2bbfdcd12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "275aac6149cd41da9ec8b73091473e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0bacc5d760e44b58bc9100f4a96b9a46",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4bc53e6ad36e4cdabe122123dfbc1041",
              "IPY_MODEL_e2e2457761904deb8ecaf05caef5c4f1"
            ]
          }
        },
        "0bacc5d760e44b58bc9100f4a96b9a46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4bc53e6ad36e4cdabe122123dfbc1041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6556163e8a3c4371a0f33328dd368fc6",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29d44cd262024ac8babfc832a7c3b938"
          }
        },
        "e2e2457761904deb8ecaf05caef5c4f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_18f36badd5c9406f8467afe3bc5ca932",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 361/361 [00:00&lt;00:00, 8.62kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_52c692161c9841f5934ae846d0b258f4"
          }
        },
        "6556163e8a3c4371a0f33328dd368fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29d44cd262024ac8babfc832a7c3b938": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18f36badd5c9406f8467afe3bc5ca932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "52c692161c9841f5934ae846d0b258f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de532a655e8c4fe89523611c43030a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_953051cccac748ba8e8daded50880efa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_58a26a41a385427e957eb107c93bf6f5",
              "IPY_MODEL_8ab52b5f943b414e9be9522782567eaf"
            ]
          }
        },
        "953051cccac748ba8e8daded50880efa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58a26a41a385427e957eb107c93bf6f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f38f31800082448eb37c4b771054fc1d",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1c0d34e0b444802850056298a9fb96c"
          }
        },
        "8ab52b5f943b414e9be9522782567eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d0a5f9bfde9542f8b222ade23c38d738",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 436M/436M [00:07&lt;00:00, 61.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_335ba2a5864841b7bd8ed015cea3ebc2"
          }
        },
        "f38f31800082448eb37c4b771054fc1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1c0d34e0b444802850056298a9fb96c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0a5f9bfde9542f8b222ade23c38d738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "335ba2a5864841b7bd8ed015cea3ebc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bamtak/ammi-nlp/blob/master/masked_lms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYAP0oVqfav8",
        "colab_type": "text"
      },
      "source": [
        "# Masked Language Modeling\n",
        "\n",
        "In this lab, we will overview the **masked language modeling** objective, and how the **Transformer** architecture is used for large-scale masked language modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXaq-FOVfhjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5601b863-0d28-4931-9390-6d6651cc8732"
      },
      "source": [
        "!wget \"https://nyu.box.com/shared/static/axapd6s8x7pzw4kzgq3t2xzqqx35ldy4.zip\" -O \"mask_lm_lab.zip\"\n",
        "!unzip \"./mask_lm_lab.zip\" -d \"./\"\n",
        "!cp -a \"./mask_lm_lab/.\" \"./\"\n",
        "!rm -rf \"./mask_lm_lab\"\n",
        "!rm \"mask_lm_lab.zip\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-18 16:39:47--  https://nyu.box.com/shared/static/axapd6s8x7pzw4kzgq3t2xzqqx35ldy4.zip\n",
            "Resolving nyu.box.com (nyu.box.com)... 107.152.29.197\n",
            "Connecting to nyu.box.com (nyu.box.com)|107.152.29.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/axapd6s8x7pzw4kzgq3t2xzqqx35ldy4.zip [following]\n",
            "--2020-03-18 16:39:47--  https://nyu.box.com/public/static/axapd6s8x7pzw4kzgq3t2xzqqx35ldy4.zip\n",
            "Reusing existing connection to nyu.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://nyu.app.box.com/public/static/axapd6s8x7pzw4kzgq3t2xzqqx35ldy4.zip [following]\n",
            "--2020-03-18 16:39:47--  https://nyu.app.box.com/public/static/axapd6s8x7pzw4kzgq3t2xzqqx35ldy4.zip\n",
            "Resolving nyu.app.box.com (nyu.app.box.com)... 107.152.29.199\n",
            "Connecting to nyu.app.box.com (nyu.app.box.com)|107.152.29.199|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://public.boxcloud.com/d/1/b1!rKVWWKWj7qyLs3dutMnDR35k5NR3RcNiDnL3KzsOK83ap0-mfEISkM00wHykxOyqshOJTt6aIC4qO7P0Ho_hp2cwQ5gV9as0CilyYrlsu02RdK8Q6KfIanOV9PhxRFIYETEcRHA8zDwArigdYlOOjNsP8o4ZX3EvY0u-7wCETjZvWgOp0K7XCZWOqOaha5xze36aJ83z9SUw7QDOPQnXIs8wR_rtPLhzu-o69_9OJg4w6U9k81nxLpAXex5YQRe6lNsshSVqFod2k7i8Jom1YK9EZ2VtcrINeojrD7l3LqQ8wV9jYJOfcHSd80H2_M-NdRp_0bhJUGO8W94AdV4JkidE7ihGwdrBSNvM9sftDYlti7YtmkUYqaGUWq8TvPLv1BK6ajrIVZdzj2QLt1pvxcB8poiM3pnetPepyyj7p90zrLKn4l1gXdgeO9Wuzuj-aU6YuOgdhYtKidy3LtXqIdC9doiy8nEgk4NBOgwNJ9NAhvLvYCtvqa7v-CI4rjkK0vHYZJe1oNo2GDPcWKzp2f7_QCE-UMNMvUHofYq3tPpjQ5pPaLUaV8txuRBqtDBRH2-1wykaYi61goQ9qhWGOpoCPjkuxQH-jc29rXCfW3ORevZqXA0lEiU46EuaMaq4uah_yOAHuMcYPvJ-Dvhti5EgWxGJyhUbhgim7sIh5roeKhVFOXQrLr8yZfmb8sVJk_7G28zfgdAXqfdpr9ojno2aSi0wcw09PZOSu71KSMLS0batst2Ff9MLgzyKWGktLXXxNNSxVatxtMuQv5xldZXSFSZMVKdXzLsjWbj1PTmZ_1llg9ReKC66U-dTYVO9sOljeDtFOS2om00gprrxcAGwx66o02HX9_R8FQrgaa2AbKWv_sBWRqIVYH_7AZR26I3hlnR77sp3y0zh5v5s0UPUwebRJKe8Zkd8AJZkrBXiJewqLpwQSJo8wbvZlX0wJDXb-uCXG0WnZsY55n29F6BDJJHJLkaSDSYwiIAJIrs4yvTttQ13aeTW7O9uj0UeeYmNoYIapyVe1Y8acSJcooEZfEfDn6zAcRIXmgBeLHTsy1v3d2OesAb4UxZLAj5Ls_IMGtgmTTLJStab5je4hNCn_mDfQhIAP-ef8Rurj1zwyMkcWTqmLGwSI7BlH3BNS1NEmm7OFwXNqFLdpEIBqlAdjLHe-jFcNesRxLhyM5txyHoJZlcdWCMCDRDUC9Pt7uVasGFgHfUVqstyl7YGVXqZUiG2VER7tOlATOoIGa1CwggDE9GtoDkdmQuqTUy1UtdLa4yDPtHz2KVcPaBYslD1xl61uS2ffS-8H0buNK9iV57fw9MBTx3k-cQvJgTdyJElD-BB9Pk00Hau9ysW2y1l5-c4jEDYenEqur-hpv4jVoIZkBXan0L2tHw2_Imq4S2wd5pwrLXZEoiDwSe9xSy-Uio9cyO98O6H/download [following]\n",
            "--2020-03-18 16:39:48--  https://public.boxcloud.com/d/1/b1!rKVWWKWj7qyLs3dutMnDR35k5NR3RcNiDnL3KzsOK83ap0-mfEISkM00wHykxOyqshOJTt6aIC4qO7P0Ho_hp2cwQ5gV9as0CilyYrlsu02RdK8Q6KfIanOV9PhxRFIYETEcRHA8zDwArigdYlOOjNsP8o4ZX3EvY0u-7wCETjZvWgOp0K7XCZWOqOaha5xze36aJ83z9SUw7QDOPQnXIs8wR_rtPLhzu-o69_9OJg4w6U9k81nxLpAXex5YQRe6lNsshSVqFod2k7i8Jom1YK9EZ2VtcrINeojrD7l3LqQ8wV9jYJOfcHSd80H2_M-NdRp_0bhJUGO8W94AdV4JkidE7ihGwdrBSNvM9sftDYlti7YtmkUYqaGUWq8TvPLv1BK6ajrIVZdzj2QLt1pvxcB8poiM3pnetPepyyj7p90zrLKn4l1gXdgeO9Wuzuj-aU6YuOgdhYtKidy3LtXqIdC9doiy8nEgk4NBOgwNJ9NAhvLvYCtvqa7v-CI4rjkK0vHYZJe1oNo2GDPcWKzp2f7_QCE-UMNMvUHofYq3tPpjQ5pPaLUaV8txuRBqtDBRH2-1wykaYi61goQ9qhWGOpoCPjkuxQH-jc29rXCfW3ORevZqXA0lEiU46EuaMaq4uah_yOAHuMcYPvJ-Dvhti5EgWxGJyhUbhgim7sIh5roeKhVFOXQrLr8yZfmb8sVJk_7G28zfgdAXqfdpr9ojno2aSi0wcw09PZOSu71KSMLS0batst2Ff9MLgzyKWGktLXXxNNSxVatxtMuQv5xldZXSFSZMVKdXzLsjWbj1PTmZ_1llg9ReKC66U-dTYVO9sOljeDtFOS2om00gprrxcAGwx66o02HX9_R8FQrgaa2AbKWv_sBWRqIVYH_7AZR26I3hlnR77sp3y0zh5v5s0UPUwebRJKe8Zkd8AJZkrBXiJewqLpwQSJo8wbvZlX0wJDXb-uCXG0WnZsY55n29F6BDJJHJLkaSDSYwiIAJIrs4yvTttQ13aeTW7O9uj0UeeYmNoYIapyVe1Y8acSJcooEZfEfDn6zAcRIXmgBeLHTsy1v3d2OesAb4UxZLAj5Ls_IMGtgmTTLJStab5je4hNCn_mDfQhIAP-ef8Rurj1zwyMkcWTqmLGwSI7BlH3BNS1NEmm7OFwXNqFLdpEIBqlAdjLHe-jFcNesRxLhyM5txyHoJZlcdWCMCDRDUC9Pt7uVasGFgHfUVqstyl7YGVXqZUiG2VER7tOlATOoIGa1CwggDE9GtoDkdmQuqTUy1UtdLa4yDPtHz2KVcPaBYslD1xl61uS2ffS-8H0buNK9iV57fw9MBTx3k-cQvJgTdyJElD-BB9Pk00Hau9ysW2y1l5-c4jEDYenEqur-hpv4jVoIZkBXan0L2tHw2_Imq4S2wd5pwrLXZEoiDwSe9xSy-Uio9cyO98O6H/download\n",
            "Resolving public.boxcloud.com (public.boxcloud.com)... 107.152.25.200\n",
            "Connecting to public.boxcloud.com (public.boxcloud.com)|107.152.25.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 123507482 (118M) [application/zip]\n",
            "Saving to: â€˜mask_lm_lab.zipâ€™\n",
            "\n",
            "mask_lm_lab.zip     100%[===================>] 117.79M  17.1MB/s    in 6.2s    \n",
            "\n",
            "2020-03-18 16:39:54 (18.9 MB/s) - â€˜mask_lm_lab.zipâ€™ saved [123507482/123507482]\n",
            "\n",
            "Archive:  ./mask_lm_lab.zip\n",
            "   creating: ./mask_lm_lab/\n",
            "  inflating: ./mask_lm_lab/masked_lms.ipynb  \n",
            "   creating: ./mask_lm_lab/img/\n",
            "  inflating: ./mask_lm_lab/img/layers.png  \n",
            "  inflating: ./mask_lm_lab/img/attention.png  \n",
            "  inflating: ./mask_lm_lab/img/bert_citations.png  \n",
            "  inflating: ./mask_lm_lab/img/fflm.png  \n",
            "  inflating: ./mask_lm_lab/img/high2.png  \n",
            "  inflating: ./mask_lm_lab/img/high1.png  \n",
            "  inflating: ./mask_lm_lab/img/layer.png  \n",
            "  inflating: ./mask_lm_lab/img/bert_overview.png  \n",
            "  inflating: ./mask_lm_lab/img/mlm.png  \n",
            "  inflating: ./mask_lm_lab/img/bert_kb.png  \n",
            "  inflating: ./mask_lm_lab/img/bert_inputs.png  \n",
            "  inflating: ./mask_lm_lab/utils.py  \n",
            "   creating: ./mask_lm_lab/model/\n",
            "  inflating: ./mask_lm_lab/model/model_best.pt  \n",
            "  inflating: ./mask_lm_lab/train.py  \n",
            "   creating: ./mask_lm_lab/data/\n",
            "   creating: ./mask_lm_lab/data/TREx/\n",
            "  inflating: ./mask_lm_lab/data/TREx/P740.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P108.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P190.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P27.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P1376.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P131.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P937.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P176.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P463.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P20.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P136.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P39.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P407.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P527.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P276.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P19.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P47.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P101.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P1303.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P17.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P127.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P103.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P31.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P159.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P530.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P495.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P37.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P138.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P361.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P140.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P1001.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P30.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P178.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P279.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P449.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P364.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P1412.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P264.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P36.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P106.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/TREx/P413.jsonl  \n",
            "   creating: ./mask_lm_lab/data/Google_RE/\n",
            "  inflating: ./mask_lm_lab/data/Google_RE/place_of_birth_test.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/Google_RE/date_of_birth_test.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/Google_RE/place_of_death_test.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/personachat_all_sentences_valid.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/personachat_all_sentences_train.jsonl  \n",
            "   creating: ./mask_lm_lab/data/Squad/\n",
            "  inflating: ./mask_lm_lab/data/Squad/test.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/relations.jsonl  \n",
            "   creating: ./mask_lm_lab/data/ConceptNet/\n",
            "  inflating: ./mask_lm_lab/data/ConceptNet/test.jsonl  \n",
            "  inflating: ./mask_lm_lab/data/vocab.pkl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3ZXGLQUfav_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7103d8db-c69a-46cd-b212-583e3f6e2267"
      },
      "source": [
        "%pylab inline\n",
        "import os, sys, glob, json, math\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from pprint import pprint\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy8Y1BPZfawE",
        "colab_type": "text"
      },
      "source": [
        "## Background\n",
        "\n",
        "Recently, Devlin et al. published [BERT: Pre-training of Deep Bidirectional Transformers for\n",
        "Language Understanding](https://arxiv.org/pdf/1810.04805.pdf).\n",
        "\n",
        "\n",
        "**B**idirectional\n",
        "\n",
        "**E**ncoder\n",
        "\n",
        "**R**epresentations from\n",
        "\n",
        "**T**ransformers\n",
        "\n",
        "\n",
        "#### Goal: \n",
        "1. **pre-train** a model that produces language representations. \n",
        "2. **fine-tune** the model on a task.\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o3q02yHfawF",
        "colab_type": "text"
      },
      "source": [
        "## Masked Language Model Objective\n",
        "\n",
        "Randomly mask some of the tokens from the input, predict original vocabulary id of each masked token.\n",
        "\n",
        "- Given sequence $x_1,\\ldots,x_N$.\n",
        "\n",
        "- Form **mask** $m_1,\\ldots,m_N$ where $m_i\\in \\{0,1\\}$.\n",
        "    - E.g. $m_i=1$ with probability 0.15\n",
        "    \n",
        "- Form **masked sequence** $\\tilde{x}_1,\\ldots,\\tilde{x}_N$.\n",
        "    - $\\tilde{x}_i=\\begin{cases} x_i & m_i=0\\\\ \\texttt{[MASK]} & m_i=1\\end{cases}$\n",
        "\n",
        "\n",
        "#### $$\\mathcal{L}_{\\text{MLM}}=-\\sum_{\\underbrace{i | m_i=1}_{\\text{MASKED POSITIONS}}}\\log p_{\\theta}(\\underbrace{x_i}_{\\text{TRUE TOKEN}}|\\underbrace{\\tilde{x}_1,\\ldots,\\tilde{x}_N}_{\\text{MASKED SEQUENCE}})$$\n",
        "\n",
        "\n",
        "<!-- Below, we will discuss the exact form of $\\tilde{x}_i$ that the BERT authors used. -->\n",
        "\n",
        "\n",
        "<!-- #### Diagram of BERT Implementation -->\n",
        "<!-- ![](bert_overview.png) -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oefNdVHfawG",
        "colab_type": "text"
      },
      "source": [
        "## Transformers\n",
        "\n",
        "So far we have modeled a sequence by factorizing the joint distribution into conditionals, and **parameterizing each conditional with a recurrent network**:\n",
        "\n",
        "\n",
        "#### $$p_{\\theta}(x_1,\\ldots,x_T)=\\prod_{t=1}^T p_{\\theta}(x_t | x_{<t})$$\n",
        "\\begin{align}\n",
        "h_t &= RNN(x_{t-1}, h_t)\\\\\n",
        "p_{\\theta}(x_t | x_{<t}) &=\\text{softmax}\\left(Wh_t+b\\right),\n",
        "\\end{align}\n",
        "\n",
        "where $\\theta$ are the model parameters (RNN parameters, $W, b$, embedding matrix).\n",
        "\n",
        "\n",
        "#### Alternative\n",
        "\n",
        "An alternative proposed in [[Vaswani et al 2017](https://arxiv.org/pdf/1706.03762.pdf)] is to parameterize each conditional with a **particular feed-forward architecture** called the **Transformer**. With this model, it is possible to compute all conditionals with a **single feed-forward pass**:\n",
        "\\begin{align}\n",
        "(h_1,\\ldots,h_T) &= Transformer(x)\\\\\n",
        "p_{\\theta}(x_t | x_{<t}) &= \\text{softmax}\\left(Wh_t + b\\right)\n",
        "\\end{align}\n",
        "\n",
        "We will discuss briefly the key ideas, the overall Transformer architecture (encoder only), and how they are used in Pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbiM-SdVfawH",
        "colab_type": "text"
      },
      "source": [
        "### High-Level View\n",
        "\n",
        "We can view the Transformer encoder as mapping a sequence to a sequence of vectors.\n",
        "\n",
        "<img src=\"img/high1.png\" alt=\"Drawing\" style=\"width: 35%;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM5F6HiPfawJ",
        "colab_type": "text"
      },
      "source": [
        "Let's step through the key ideas of how this mapping is designed, and discuss some of its resulting properties."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2T69vCHfawK",
        "colab_type": "text"
      },
      "source": [
        "### Key Idea 1: Position Embeddings\n",
        "\n",
        "Unlike RNNs which can learn positional information via the hidden state over time, the Transformer has no notion of time.\n",
        "\n",
        "Thus we encode inputs with **position** as well as **token** embeddings:\n",
        "\n",
        "<img src=\"img/high2.png\" alt=\"Drawing\" style=\"width: 35%;\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HR4h3W_fawL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = ['<s>', 'my', 'pet', '[M]', '<s>']\n",
        "\n",
        "max_len = 10\n",
        "\n",
        "vocab = {'<s>': 0, 'my': 1, 'pet': 2, 'dog': 3, 'cat': 4, 'lion': 5, '[M]': 6}\n",
        "\n",
        "dim = 6\n",
        "\n",
        "token_embed = nn.Embedding(len(vocab), embedding_dim=dim)\n",
        "position_embed = nn.Embedding(max_len, embedding_dim=dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TNj_wFEfawP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d68a5eea-e3a2-480d-b1f8-a7b9a2118673"
      },
      "source": [
        "input_vector = torch.tensor([vocab[x] for x in input_sequence]).unsqueeze(1)\n",
        "\n",
        "input_embeddings = token_embed(input_vector) + position_embed(torch.arange(len(input_vector)))\n",
        "input_embeddings.size()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSSeLqzkfawT",
        "colab_type": "text"
      },
      "source": [
        "**Warning!!** The pytorch Transformer classes accept input as `Length x Batch x Dim`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIPgSidffawV",
        "colab_type": "text"
      },
      "source": [
        "#### Key Idea 2: Modularity\n",
        "The Transformer (encoder) is composed of a stack of **N identical layers**.\n",
        "\n",
        "<img src=\"img/layers.png\" alt=\"Drawing\" style=\"width: 35%;\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBgqgF0RfawW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "nn.TransformerEncoder?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK3vNszgfawa",
        "colab_type": "text"
      },
      "source": [
        "#### The `forward` passes the input through the N layers, then normalizes it:\n",
        "\n",
        "**Warning!!** The forward function accepts input as `Length x Batch x Dim`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRd_osGNfawc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nn.TransformerEncoder.forward??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOItOZt-fawf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=2, dim_feedforward=64, dropout=0.1)\n",
        "\n",
        "encoder = nn.TransformerEncoder(encoder_layer, num_layers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmeo0J5Lfawi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "39b98393-adda-48f6-b409-bb12eaccd927"
      },
      "source": [
        "outputs = encoder(input_embeddings)\n",
        "\n",
        "print(\"input size: \\t%s\" % str(tuple(input_embeddings.shape)))\n",
        "print(\"output size:\\t%s\" % str(tuple(outputs.shape)))\n",
        "outputs"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input size: \t(5, 5, 6)\n",
            "output size:\t(5, 5, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.3119, -0.1663,  0.5734,  1.4156,  0.3403, -1.8511],\n",
              "         [ 1.4180,  0.7557, -1.1261, -0.5396,  0.6761, -1.1840],\n",
              "         [-0.3921,  0.2300,  0.8808, -0.5381,  1.4446, -1.6252],\n",
              "         [-0.9952, -0.5162,  1.0020, -0.7071,  1.7261, -0.5096],\n",
              "         [ 0.5920,  0.3546, -0.4663,  1.2125,  0.2499, -1.9426]],\n",
              "\n",
              "        [[-0.3313, -0.6227,  0.5338,  1.8202, -0.0203, -1.3798],\n",
              "         [ 1.4673, -0.0097, -0.7136, -0.3712,  1.0647, -1.4375],\n",
              "         [-1.5142, -0.1103,  0.6228,  0.3107,  1.5645, -0.8735],\n",
              "         [-1.5983, -0.8959,  0.2154,  0.2171,  1.4912,  0.5705],\n",
              "         [-0.6355, -0.4592,  0.3355,  1.7309,  0.4641, -1.4357]],\n",
              "\n",
              "        [[ 0.4115, -0.1010, -0.6748,  1.9035, -0.2417, -1.2974],\n",
              "         [ 1.5888,  0.3171, -1.2594, -0.4769,  0.7947, -0.9643],\n",
              "         [ 0.7270,  0.2961, -0.9664,  0.8440,  0.8404, -1.7411],\n",
              "         [ 0.2897, -0.7545,  1.1356, -0.3920,  1.2506, -1.5295],\n",
              "         [ 0.6238, -0.0915, -0.8111,  1.8132, -0.2774, -1.2570]],\n",
              "\n",
              "        [[-0.4758, -0.3243, -0.3562,  2.2018, -0.2515, -0.7939],\n",
              "         [ 1.4028,  0.2240, -1.4787,  0.5021,  0.4909, -1.1411],\n",
              "         [-1.5632,  0.2085, -0.5403,  1.3819,  1.0246, -0.5116],\n",
              "         [-1.9845, -0.1909, -0.0218,  0.6398,  1.2273,  0.3300],\n",
              "         [-0.1886, -0.4267, -0.2030,  2.1807, -0.5116, -0.8508]],\n",
              "\n",
              "        [[ 0.2033,  0.0044, -0.2804,  1.7054,  0.0888, -1.7215],\n",
              "         [ 1.7489,  0.3575, -1.0182,  0.0638,  0.1688, -1.3208],\n",
              "         [-0.1146,  0.7792,  0.0487, -0.0618,  1.2807, -1.9322],\n",
              "         [-1.1332, -0.3387,  0.9242, -1.0590,  1.6202, -0.0134],\n",
              "         [ 0.3497, -0.0924, -0.4527,  1.7464,  0.0645, -1.6155]]],\n",
              "       grad_fn=<NativeLayerNormBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVqj46pefawm",
        "colab_type": "text"
      },
      "source": [
        "#### Each layer has two parts, **self-attention** and a feed-forward transformation:\n",
        "\n",
        "<img src=\"img/layer.png\" alt=\"Drawing\" style=\"width: 65%;\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MjF4qp4fawn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nn.TransformerEncoderLayer??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK9ivt5cfawr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nn.TransformerEncoderLayer.forward??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhwFmgHVfawu",
        "colab_type": "text"
      },
      "source": [
        "### Key Idea 3: Self-Attention\n",
        "\n",
        "In the RNN, the hidden state contains information about previous tokens.\n",
        "The Transformer instead performs **attention** over all inputs at a given layer. 'Attention' computes an output vector by taking a weighted sum of input vectors. The weights are 'attention weights'. The Transformer uses **scaled dot-product attention**:\n",
        "#### $$\\text{Attention}(Q,K,V)=\\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
        "\n",
        "and 'Multi-head Attention' refers to applying several of these operations in parallel.\n",
        "\n",
        "#### *Key Property*: Each output vector of a layer $n$ can using information from **all** inputs to the layer $n$.\n",
        "\n",
        "Thus each **final output vector** can incorporate information from **all input words**.\n",
        "\n",
        "(If we want to prevent information flow such as in left-to-right language modeling, we can use masking)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wRX3Ttifawv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc4b0748-ff12-4063-b89d-2c2dc6bbdb8f"
      },
      "source": [
        "attn = nn.MultiheadAttention(dim, 2, dropout=0.0)\n",
        "\n",
        "attn_outputs, attn_weights = attn.forward(query=outputs, key=outputs, value=outputs)\n",
        "\n",
        "print(\"input shape: %s\" % (str(tuple(outputs.size()))))\n",
        "print(\"output shape: %s\" % (str(tuple(attn_outputs.size()))))\n",
        "print(outputs)\n",
        "\n",
        "print(\"\\nattn weights shape: %s\" % (str(tuple(attn_weights.size()))))\n",
        "print(attn_weights)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape: (5, 5, 6)\n",
            "output shape: (5, 5, 6)\n",
            "tensor([[[-0.3119, -0.1663,  0.5734,  1.4156,  0.3403, -1.8511],\n",
            "         [ 1.4180,  0.7557, -1.1261, -0.5396,  0.6761, -1.1840],\n",
            "         [-0.3921,  0.2300,  0.8808, -0.5381,  1.4446, -1.6252],\n",
            "         [-0.9952, -0.5162,  1.0020, -0.7071,  1.7261, -0.5096],\n",
            "         [ 0.5920,  0.3546, -0.4663,  1.2125,  0.2499, -1.9426]],\n",
            "\n",
            "        [[-0.3313, -0.6227,  0.5338,  1.8202, -0.0203, -1.3798],\n",
            "         [ 1.4673, -0.0097, -0.7136, -0.3712,  1.0647, -1.4375],\n",
            "         [-1.5142, -0.1103,  0.6228,  0.3107,  1.5645, -0.8735],\n",
            "         [-1.5983, -0.8959,  0.2154,  0.2171,  1.4912,  0.5705],\n",
            "         [-0.6355, -0.4592,  0.3355,  1.7309,  0.4641, -1.4357]],\n",
            "\n",
            "        [[ 0.4115, -0.1010, -0.6748,  1.9035, -0.2417, -1.2974],\n",
            "         [ 1.5888,  0.3171, -1.2594, -0.4769,  0.7947, -0.9643],\n",
            "         [ 0.7270,  0.2961, -0.9664,  0.8440,  0.8404, -1.7411],\n",
            "         [ 0.2897, -0.7545,  1.1356, -0.3920,  1.2506, -1.5295],\n",
            "         [ 0.6238, -0.0915, -0.8111,  1.8132, -0.2774, -1.2570]],\n",
            "\n",
            "        [[-0.4758, -0.3243, -0.3562,  2.2018, -0.2515, -0.7939],\n",
            "         [ 1.4028,  0.2240, -1.4787,  0.5021,  0.4909, -1.1411],\n",
            "         [-1.5632,  0.2085, -0.5403,  1.3819,  1.0246, -0.5116],\n",
            "         [-1.9845, -0.1909, -0.0218,  0.6398,  1.2273,  0.3300],\n",
            "         [-0.1886, -0.4267, -0.2030,  2.1807, -0.5116, -0.8508]],\n",
            "\n",
            "        [[ 0.2033,  0.0044, -0.2804,  1.7054,  0.0888, -1.7215],\n",
            "         [ 1.7489,  0.3575, -1.0182,  0.0638,  0.1688, -1.3208],\n",
            "         [-0.1146,  0.7792,  0.0487, -0.0618,  1.2807, -1.9322],\n",
            "         [-1.1332, -0.3387,  0.9242, -1.0590,  1.6202, -0.0134],\n",
            "         [ 0.3497, -0.0924, -0.4527,  1.7464,  0.0645, -1.6155]]],\n",
            "       grad_fn=<NativeLayerNormBackward>)\n",
            "\n",
            "attn weights shape: (5, 5, 5)\n",
            "tensor([[[0.2033, 0.2289, 0.1817, 0.2089, 0.1772],\n",
            "         [0.2049, 0.2306, 0.1837, 0.2044, 0.1764],\n",
            "         [0.2257, 0.2188, 0.1824, 0.1850, 0.1881],\n",
            "         [0.2050, 0.2231, 0.1892, 0.2006, 0.1821],\n",
            "         [0.2193, 0.2226, 0.1805, 0.1940, 0.1837]],\n",
            "\n",
            "        [[0.2273, 0.2116, 0.2104, 0.1776, 0.1731],\n",
            "         [0.2155, 0.2132, 0.2056, 0.1853, 0.1803],\n",
            "         [0.2266, 0.2127, 0.2118, 0.1769, 0.1721],\n",
            "         [0.2104, 0.2260, 0.2088, 0.1817, 0.1730],\n",
            "         [0.2119, 0.2265, 0.1998, 0.1832, 0.1786]],\n",
            "\n",
            "        [[0.1842, 0.2223, 0.1774, 0.2434, 0.1727],\n",
            "         [0.1687, 0.2241, 0.1950, 0.2604, 0.1518],\n",
            "         [0.2136, 0.2301, 0.1684, 0.1962, 0.1916],\n",
            "         [0.1799, 0.2289, 0.1937, 0.2400, 0.1575],\n",
            "         [0.1961, 0.2305, 0.1657, 0.2281, 0.1796]],\n",
            "\n",
            "        [[0.1728, 0.2438, 0.1442, 0.2398, 0.1994],\n",
            "         [0.1698, 0.2584, 0.1463, 0.2245, 0.2010],\n",
            "         [0.1893, 0.2146, 0.1919, 0.2184, 0.1859],\n",
            "         [0.1691, 0.2622, 0.1481, 0.2204, 0.2002],\n",
            "         [0.1723, 0.2417, 0.1357, 0.2436, 0.2067]],\n",
            "\n",
            "        [[0.1864, 0.2422, 0.1810, 0.1950, 0.1954],\n",
            "         [0.1565, 0.2212, 0.1927, 0.2416, 0.1881],\n",
            "         [0.1877, 0.2438, 0.1845, 0.1867, 0.1973],\n",
            "         [0.1693, 0.2321, 0.1920, 0.2121, 0.1944],\n",
            "         [0.1773, 0.2416, 0.1849, 0.2022, 0.1940]]], grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjxzCF55fawz",
        "colab_type": "text"
      },
      "source": [
        "#### Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbL9xpJwfaw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, vocab_size, max_len, dim=8, num_layers=4, nhead=2):\n",
        "        super().__init__()\n",
        "        self.token_embed = nn.Embedding(vocab_size, dim)\n",
        "        self.position_embed = nn.Embedding(max_len, dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=nhead, dim_feedforward=64, dropout=0.0)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.projection = nn.Linear(dim, vocab_size)\n",
        "    \n",
        "    def features(self, token_indices):\n",
        "        pos = torch.arange(len(token_indices), device=token_indices.device).unsqueeze(1)\n",
        "        x = self.token_embed(token_indices) + self.position_embed(pos)\n",
        "        x = self.encoder(x)\n",
        "        return x\n",
        "    \n",
        "    def forward(self, token_indices):\n",
        "        x = self.features(token_indices)\n",
        "        x = self.projection(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlKHedEdfaw8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f7d1779-18e7-4e92-9596-501f055dfdbe"
      },
      "source": [
        "input_vector.size()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOPFwaf2faxB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "8106c190-f681-424f-f17c-bad8c6738d58"
      },
      "source": [
        "model = Transformer(len(vocab), max_len=100)\n",
        "\n",
        "model.features(input_vector)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.2944, -1.0542,  0.9190,  0.8104,  0.1922, -1.3439,  0.4669,\n",
              "          -1.2848]],\n",
              "\n",
              "        [[ 0.0662,  0.9383,  0.7310, -2.1762,  0.3383, -0.9772,  0.8502,\n",
              "           0.2296]],\n",
              "\n",
              "        [[ 1.1789,  0.7301, -1.9893,  0.3174, -0.8781,  0.0353,  1.0320,\n",
              "          -0.4264]],\n",
              "\n",
              "        [[-0.4475,  0.7608, -1.0874, -0.3018, -1.5479,  0.3193,  0.5221,\n",
              "           1.7824]],\n",
              "\n",
              "        [[-0.0421,  0.0906, -0.2850,  1.6936, -1.1847, -0.6937,  1.4490,\n",
              "          -1.0277]]], grad_fn=<NativeLayerNormBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62fzJdt4faxE",
        "colab_type": "text"
      },
      "source": [
        "## Back to Masked Language Modeling\n",
        "\n",
        "Recall the **key property** of Transformers: due to self-attention, each output vector can incorporate information from *all* input tokens.\n",
        "\n",
        "<img src=\"img/mlm.png\" alt=\"Drawing\" style=\"width: 45%;\"/>\n",
        "\n",
        "This is useful for masked language modeling, where we want to use information from the entire context when predicting the masked token(s)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhL-mDQ0faxF",
        "colab_type": "text"
      },
      "source": [
        "#### MLM on Persona-Chat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw9eGrGziBL5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "68dbcb53-9cf8-457d-89da-e6977d3380c5"
      },
      "source": [
        "!pip install jsonlines"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jsonlines) (1.12.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuXt7wSAfaxG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f5dc835d-d659-4361-8271-a3670a74444c"
      },
      "source": [
        "import utils\n",
        "raw_datasets, datasets, vocab = utils.load_personachat()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133176/133176 [00:00<00:00, 197013.18it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16181/16181 [00:00<00:00, 226509.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 19157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzAOF0uJfaxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "trainloader = DataLoader(datasets['train'], batch_size=4, collate_fn=lambda x: utils.pad_collate_fn(vocab.get_id('<pad>'), x))\n",
        "validloader = DataLoader(datasets['valid'], batch_size=4, collate_fn=lambda x: utils.pad_collate_fn(vocab.get_id('<pad>'), x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn610FhafaxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "25d86ec3-e338-49dc-d080-942fb7977a17"
      },
      "source": [
        "batch = next(trainloader.__iter__())\n",
        "batch"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0,  0],\n",
              "        [ 4,  4,  4, 22],\n",
              "        [ 5,  5, 18, 23],\n",
              "        [ 6, 13, 17, 24],\n",
              "        [ 7, 14, 19, 15],\n",
              "        [ 8, 15, 13, 25],\n",
              "        [ 9, 16, 20, 26],\n",
              "        [10, 17, 21, 27],\n",
              "        [11, 12, 12, 28],\n",
              "        [12,  0,  0, 29],\n",
              "        [ 0,  2,  2, 30],\n",
              "        [ 2,  2,  2, 24],\n",
              "        [ 2,  2,  2,  4],\n",
              "        [ 2,  2,  2, 31],\n",
              "        [ 2,  2,  2, 32],\n",
              "        [ 2,  2,  2, 27],\n",
              "        [ 2,  2,  2, 33],\n",
              "        [ 2,  2,  2, 34],\n",
              "        [ 2,  2,  2, 35],\n",
              "        [ 2,  2,  2, 36],\n",
              "        [ 2,  2,  2, 24],\n",
              "        [ 2,  2,  2,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHGunEdYfaxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mask_tokens(inputs, mask_prob, pad_token_id, mask_token_id, vsize):\n",
        "    \"\"\" Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original.\"\"\"\n",
        "    inputs = inputs.clone()\n",
        "    labels = inputs.clone()\n",
        "    # Sample tokens in each sequence for masked-LM training\n",
        "    masked_indices = torch.bernoulli(torch.full(labels.shape, mask_prob)).bool()\n",
        "    masked_indices = masked_indices & (inputs != pad_token_id)\n",
        "    labels[~masked_indices] = -1  # We only compute loss on masked tokens\n",
        "\n",
        "    # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
        "    indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
        "    inputs[indices_replaced] = mask_token_id\n",
        "\n",
        "    # 10% of the time, we replace masked input tokens with random word\n",
        "    indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
        "    random_words = torch.randint(vsize, labels.shape, dtype=torch.long)\n",
        "    inputs[indices_random] = random_words[indices_random]\n",
        "\n",
        "    # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
        "    return inputs, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COVdaxiafaxT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "f66ccd6d-3f36-4e92-e7eb-da091af6a90d"
      },
      "source": [
        "inputs, labels = mask_tokens(batch, mask_prob=0.15, mask_token_id=vocab.get_id('[M]'), pad_token_id=vocab.get_id('<pad>'), vsize=len(vocab))\n",
        "print(\"Mask token id: %d\" % vocab.get_id('[M]'))\n",
        "inputs"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mask token id: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  0,  0],\n",
              "        [ 4,  1,  4, 22],\n",
              "        [ 5,  1,  1, 23],\n",
              "        [ 6, 13, 17, 24],\n",
              "        [ 7, 14, 19, 15],\n",
              "        [ 8, 15, 13, 25],\n",
              "        [ 1, 16, 20, 26],\n",
              "        [ 1, 17, 21, 27],\n",
              "        [11, 12, 12, 28],\n",
              "        [12,  0,  0, 29],\n",
              "        [ 0,  2,  2, 30],\n",
              "        [ 2,  2,  2, 24],\n",
              "        [ 2,  2,  2,  1],\n",
              "        [ 2,  2,  2, 31],\n",
              "        [ 2,  2,  2, 32],\n",
              "        [ 2,  2,  2, 27],\n",
              "        [ 2,  2,  2, 33],\n",
              "        [ 2,  2,  2, 34],\n",
              "        [ 2,  2,  2, 35],\n",
              "        [ 2,  2,  2, 36],\n",
              "        [ 2,  2,  2, 24],\n",
              "        [ 2,  2,  2,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PV2gVkzfaxX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "e4d1b99b-7079-425a-d6ab-e3ebc62b1f88"
      },
      "source": [
        "labels"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1,  0, -1, -1],\n",
              "        [-1,  4, -1, -1],\n",
              "        [-1,  5, 18, -1],\n",
              "        [-1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1],\n",
              "        [ 9, -1, -1, -1],\n",
              "        [10, -1, -1, -1],\n",
              "        [-1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1],\n",
              "        [-1, -1, -1,  4],\n",
              "        [-1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1],\n",
              "        [-1, -1, -1, -1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtO1jZw-faxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Transformer(len(vocab), max_len=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5vGqEqQfaxd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aaea4bf3-65ba-4b11-b0a4-78a0f4995ec7"
      },
      "source": [
        "logits = model(inputs)\n",
        "logits.size()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([22, 4, 19157])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN4rmvT8faxg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "396bfb72-70a0-4cb6-ceaa-38825f44a066"
      },
      "source": [
        "labels.size()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([22, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93MP4PN2faxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uetQCVq1faxn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96b340cf-edab-4729-e537-0d8ca6a81338"
      },
      "source": [
        "logits_ = logits.view(-1, logits.size(2))\n",
        "labels_ = labels.view(-1)\n",
        "\n",
        "criterion(logits_, labels_)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9.9377, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvCXef7ffaxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if False:\n",
        "    import torch.optim as optim\n",
        "    from tqdm import tqdm, trange\n",
        "    from collections import defaultdict\n",
        "    from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "    trainloader = DataLoader(datasets['train'], batch_size=64, collate_fn=lambda x: utils.pad_collate_fn(vocab.get_id('<pad>'), x))\n",
        "    validloader = DataLoader(datasets['valid'], batch_size=64, collate_fn=lambda x: utils.pad_collate_fn(vocab.get_id('<pad>'), x))\n",
        "\n",
        "    device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    model = Transformer(len(vocab), max_len=65, dim=256, nhead=8).to(device)\n",
        "\n",
        "    model_parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = optim.Adam(model_parameters, lr=0.001)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=-1).to(device)\n",
        "\n",
        "    stats = defaultdict(list)\n",
        "\n",
        "    for epoch in range(50):\n",
        "        for step, batch in enumerate(trainloader):\n",
        "            model.train()        \n",
        "            # Mask the batch\n",
        "            inputs, labels = mask_tokens(batch, mask_prob=0.15, \n",
        "                                         pad_token_id=vocab.get_id('<pad>'),\n",
        "                                         mask_token_id=vocab.get_id('[M]'), \n",
        "                                         vsize=len(vocab))\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            logits = model(inputs)\n",
        "            logits_ = logits.view(-1, logits.size(2))\n",
        "            labels_ = labels.view(-1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(logits_, labels_)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            stats['train_loss'].append(loss.item())\n",
        "            stats['train_loss_log'].append(loss.item())\n",
        "            if (step % 500) == 0:\n",
        "                avg_loss = sum(stats['train_loss_log']) / len(stats['train_loss_log'])\n",
        "                print(\"Epoch %d Step %d\\tTrain Loss %.3f\" % (epoch, step, avg_loss))\n",
        "                stats['train_loss_log'] = []\n",
        "\n",
        "        for batch in validloader:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                # Mask the batch\n",
        "                inputs, labels = mask_tokens(batch, mask_prob=0.15, \n",
        "                                             pad_token_id=vocab.get_id('<pad>'),\n",
        "                                             mask_token_id=vocab.get_id('[M]'), \n",
        "                                             vsize=len(vocab))\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                logits = model(inputs)\n",
        "                logits_ = logits.view(-1, logits.size(2))\n",
        "                labels_ = labels.view(-1)\n",
        "\n",
        "                loss = criterion(logits_, labels_)\n",
        "                stats['valid_loss'].append(loss.item())\n",
        "        print(\"=== Epoch %d\\tValid Loss %.3f\" % (epoch, stats['valid_loss'][-1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7mJDUBtfaxw",
        "colab_type": "text"
      },
      "source": [
        "### Example Conditionals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE2chFbOfaxy",
        "colab_type": "text"
      },
      "source": [
        "#### Load model  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW-izQe7faxz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d7efdfc-3285-4017-891a-3430ea5650c2"
      },
      "source": [
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "checkpoint = utils.load('model', 'model', best=True)\n",
        "options = checkpoint['options']\n",
        "stats = checkpoint['stats']\n",
        "\n",
        "\n",
        "model = utils.Transformer(len(vocab), options['max_len'], \n",
        "                          dim=options['dim'], \n",
        "                          nhead=options['nhead'])\n",
        "model.load_state_dict(checkpoint['model_dict'])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkOFTDHLfax3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYzg0Ve8fax6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = [['<s>', 'i', 'have', 'a', 'pet', '[M]', '.', '<s>'],\n",
        "             ['<s>', 'i', 'have', 'two', 'pet', '[M]', '.', '<s>'],\n",
        "             ['<s>', 'my', '[M]', 'is', 'a', 'lawyer', '.', '<s>'],\n",
        "             ['<s>', 'my', '[M]', 'is', 'a', '[M]', '.', '<s>'],\n",
        "             ['<s>', 'i', '[M]', '[M]', '[M]', 'sometimes', '.' , '<s>']]\n",
        "\n",
        "\n",
        "def get_top_masked_tokens(tokens, vocab, device, top=10):\n",
        "    ids = torch.tensor([vocab.get_id(x) for x in tokens], device=device).unsqueeze(1)\n",
        "    masked = ids == vocab.get_id('[M]')\n",
        "\n",
        "    logits = model(ids)[masked]\n",
        "    probs = torch.softmax(logits, -1)\n",
        "\n",
        "    print(' '.join(tokens))\n",
        "    for ps in probs:\n",
        "        probs, idxs = ps.sort(descending=True)\n",
        "\n",
        "        for i in range(top):\n",
        "            print(\"\\t%s (%.4f)\" % (vocab.get_token(idxs[i].item()),\n",
        "                                   probs[i].item()))\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fse3LY6Xfax9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99c495a8-e8d6-4c61-e8b5-0894d8e768ab"
      },
      "source": [
        "for s in sentences:\n",
        "    get_top_masked_tokens(s, vocab, device)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s> i have a pet [M] . <s>\n",
            "\tcat (0.0707)\n",
            "\tdog (0.0533)\n",
            "\tsibling (0.0342)\n",
            "\tpuppy (0.0340)\n",
            "\tsister (0.0302)\n",
            "\tretriever (0.0265)\n",
            "\tdaughter (0.0264)\n",
            "\tshepard (0.0232)\n",
            "\tnamed (0.0213)\n",
            "\tbrother (0.0208)\n",
            "\n",
            "<s> i have two pet [M] . <s>\n",
            "\tcats (0.1525)\n",
            "\tdogs (0.0874)\n",
            "\tgirls (0.0748)\n",
            "\tboys (0.0501)\n",
            "\tbrothers (0.0499)\n",
            "\twives (0.0420)\n",
            "\tchildren (0.0386)\n",
            "\tkids (0.0377)\n",
            "\tsisters (0.0333)\n",
            "\t, (0.0219)\n",
            "\n",
            "<s> my [M] is a lawyer . <s>\n",
            "\tmother (0.2872)\n",
            "\tdad (0.2481)\n",
            "\tmom (0.1561)\n",
            "\thusband (0.0864)\n",
            "\tfather (0.0363)\n",
            "\tbrother (0.0230)\n",
            "\tjob (0.0144)\n",
            "\tsister (0.0143)\n",
            "\tparents (0.0131)\n",
            "\twife (0.0104)\n",
            "\n",
            "<s> my [M] is a [M] . <s>\n",
            "\tmother (0.2330)\n",
            "\tdad (0.2212)\n",
            "\tmom (0.1373)\n",
            "\thusband (0.1110)\n",
            "\tbrother (0.0364)\n",
            "\tfather (0.0357)\n",
            "\tsister (0.0285)\n",
            "\tjob (0.0145)\n",
            "\twife (0.0141)\n",
            "\tparents (0.0127)\n",
            "\n",
            "\tteacher (0.0899)\n",
            "\tlawyer (0.0456)\n",
            "\tnurse (0.0426)\n",
            "\tcop (0.0414)\n",
            "\tmechanic (0.0386)\n",
            "\tdoctor (0.0259)\n",
            "\tpilot (0.0195)\n",
            "\tjournalist (0.0163)\n",
            "\tdancer (0.0148)\n",
            "\thairdresser (0.0123)\n",
            "\n",
            "<s> i [M] [M] [M] sometimes . <s>\n",
            "\tam (0.1669)\n",
            "\tlove (0.1151)\n",
            "\tlike (0.0823)\n",
            "\tdo (0.0610)\n",
            "\thave (0.0457)\n",
            "\tcan (0.0238)\n",
            "\thate (0.0237)\n",
            "\tjust (0.0199)\n",
            "\tget (0.0172)\n",
            "\tenjoy (0.0159)\n",
            "\n",
            "\ta (0.1115)\n",
            "\tin (0.0584)\n",
            "\tnot (0.0565)\n",
            "\tto (0.0477)\n",
            "\tmy (0.0177)\n",
            "\tthe (0.0163)\n",
            "\ti (0.0146)\n",
            "\tinto (0.0119)\n",
            "\tfor (0.0111)\n",
            "\tlike (0.0101)\n",
            "\n",
            "\t, (0.0760)\n",
            "\t. (0.0338)\n",
            "\tright (0.0203)\n",
            "\tbut (0.0201)\n",
            "\tup (0.0146)\n",
            "\tand (0.0135)\n",
            "\tnot (0.0133)\n",
            "\tmusic (0.0083)\n",
            "\tfood (0.0074)\n",
            "\tcoffee (0.0065)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Jy-ls4EfayA",
        "colab_type": "text"
      },
      "source": [
        "## Back to *BERT*\n",
        "\n",
        "**B**idirectional\n",
        "\n",
        "**E**ncoder\n",
        "\n",
        "**R**epresentations from\n",
        "\n",
        "**T**ransformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSHLMG6IfayA",
        "colab_type": "text"
      },
      "source": [
        "#### - Masked Language Modeling at scale\n",
        "\n",
        "#### - Learned representations are useful downstream\n",
        "\n",
        "<img src=\"img/bert_citations.png\" alt=\"Drawing\" style=\"width: 45%;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dPfI4UVfayB",
        "colab_type": "text"
      },
      "source": [
        "#### Great implementation in [transformers](https://github.com/huggingface/transformers):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbOO5JkJfayC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "a956b7db-f486-424d-8388-0411810008b4"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 501kB 826kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.7MB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.18)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870kB 48.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.0MB 45.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.18 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.18)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.18->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.18->boto3->transformers) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=b02aa258b16422b771ff8700ba15d2069976662aba0988b9f8e25f9e1020c401\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne9gWPOcfayE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "d9ba113e-d146-4305-ef9a-3aa47b279c62"
      },
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    BertForMaskedLM,\n",
        "    BertTokenizer\n",
        ")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYXmkfBQfayI",
        "colab_type": "text"
      },
      "source": [
        "### Details -- Model Variants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GVQg33jfayJ",
        "colab_type": "text"
      },
      "source": [
        "- $\\text{BERT}_{\\text{BASE}}$: 12 layers, hidden dimension 768, 12 attention heads (**110 million parameters**)\n",
        "- $\\text{BERT}_{\\text{LARGE}}$: 24 layers, hidden dimension 1024, 16 attention heads (**340 million parameters**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHw-0HdSfayK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "2883f074d8f644b6896ea097eddecc1b",
            "c1614d1f2fd640bb9bfd84b5e58dd4aa",
            "b978c117f5474998b517bc0605e8c4a4",
            "d19f98724b394acc8e7f56b21a06b5b0",
            "5482db849f044ac9945aafe07463db67",
            "10bcd50c36cf4d9899354a042cab0148",
            "596e239b10ec42168ceb0c72a52762ba",
            "2a8dfbc4f1e24400a2bc01d2bbfdcd12",
            "275aac6149cd41da9ec8b73091473e5a",
            "0bacc5d760e44b58bc9100f4a96b9a46",
            "4bc53e6ad36e4cdabe122123dfbc1041",
            "e2e2457761904deb8ecaf05caef5c4f1",
            "6556163e8a3c4371a0f33328dd368fc6",
            "29d44cd262024ac8babfc832a7c3b938",
            "18f36badd5c9406f8467afe3bc5ca932",
            "52c692161c9841f5934ae846d0b258f4",
            "de532a655e8c4fe89523611c43030a11",
            "953051cccac748ba8e8daded50880efa",
            "58a26a41a385427e957eb107c93bf6f5",
            "8ab52b5f943b414e9be9522782567eaf",
            "f38f31800082448eb37c4b771054fc1d",
            "c1c0d34e0b444802850056298a9fb96c",
            "d0a5f9bfde9542f8b222ade23c38d738",
            "335ba2a5864841b7bd8ed015cea3ebc2"
          ]
        },
        "outputId": "1c1857c8-6a07-4638-dfe6-004e2aec5053"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-cased', output_attentions=True)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2883f074d8f644b6896ea097eddecc1b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=213450, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "275aac6149cd41da9ec8b73091473e5a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de532a655e8c4fe89523611c43030a11",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=435779157, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNU_dDXNfayM",
        "colab_type": "text"
      },
      "source": [
        "### Details -- Input Implementation\n",
        "\n",
        "\n",
        "- `[CLS]` token: starts each sequence. Used as aggregate sequence representation.\n",
        "- `[SEP]` token: separates two segments (e.g. two sentences).\n",
        "- **Segment embedding**: learned embedding for every token indicating whether it belongs\n",
        "to sentence A or sentence B.\n",
        "- **Position embedding**: learned.\n",
        "\n",
        "\n",
        "<img src=\"img/bert_inputs.png\" alt=\"Drawing\" style=\"width: 75%;\"/>\n",
        "\n",
        "**Exercise:** Which downstream tasks would two sequences be useful for?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq8La8ktfayN",
        "colab_type": "text"
      },
      "source": [
        "### Tokenization\n",
        "\n",
        "#### BERT represents text using **subword** tokens with a 30k token vocabulary.  \n",
        "\n",
        "\n",
        "\n",
        "(more info [here](https://github.com/google/sentencepiece) and in the papers mentioned there)\n",
        "\n",
        "<!-- - **Token embedding**: WordPiece embeddings with 30k token vocabulary. -->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV2e_-GrfayN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e08ff4f8-ee62-46e0-932f-20355ce9edc5"
      },
      "source": [
        "tokenizer.tokenize(\"Pretraining is cool.\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pre', '##tra', '##ining', 'is', 'cool', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlX6co8jfayQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70adfa9b-b767-49e6-ee3b-ac6f64635197"
      },
      "source": [
        "tokenizer.tokenize(\"BERT represents text using subwords.\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B', '##ER', '##T', 'represents', 'text', 'using', 'sub', '##words', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzx_Aia8fayU",
        "colab_type": "raw"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aooAF9E4fayV",
        "colab_type": "text"
      },
      "source": [
        "### Examining Learned Conditionals (& Representations)\n",
        "\n",
        "**Probing tasks** can be used to examine aspects of what the model has learned. \n",
        "\n",
        "Following [Petroni et al 2019](https://arxiv.org/pdf/1909.01066.pdf) we probe for '**knowledge**' that the model has learned by querying for masked out objects, e.g.:\n",
        "\n",
        "<img src=\"img/bert_kb.png\" alt=\"Drawing\" style=\"width: 75%;\"/>\n",
        "\n",
        "The task also illustrates some aspects of the **conditional distributions** and **contextualized representations** that the model has learned.\n",
        "\n",
        "(image from [Petroni et al 2019])\n",
        "\n",
        "\n",
        "**Exercise:** The authors only consider *single-token* prediction. Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WjbSAD-fayW",
        "colab_type": "text"
      },
      "source": [
        "#### Probing Task\n",
        "\n",
        "We use a dataset from [Petroni et al 2019](https://github.com/facebookresearch/LAMA)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLChFiB1fayW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "60402874-6886-4ddb-9c44-323aebf17c87"
      },
      "source": [
        "import utils\n",
        "data = utils.load_lama_squad(download=True)\n",
        "data[0]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '56be4db0acb8001400a502f0_0',\n",
              " 'masked_sentences': ['To emphasize the 50th anniversary of the Super Bowl the [MASK] color was used.'],\n",
              " 'obj_label': 'gold',\n",
              " 'sub_label': 'Squad'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTuIOROgfaya",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b4b615a-3379-4c97-ea07-6e4ca5c45085"
      },
      "source": [
        "results = []\n",
        "\n",
        "model.eval()\n",
        "for example in tqdm(data, total=len(data)):\n",
        "    sentence, label = example['masked_sentences'][0], example['obj_label']\n",
        "    inp = torch.tensor([\n",
        "        [tokenizer.cls_token_id] + \n",
        "        tokenizer.encode(sentence) + \n",
        "        [tokenizer.sep_token_id]\n",
        "    ], device=device)\n",
        "    \n",
        "    mask = (inp == tokenizer.vocab[tokenizer.mask_token])\n",
        "    out, attn = model(inp)\n",
        "    \n",
        "    probs, token_ids = out[mask].softmax(1).topk(10)\n",
        "    probs = probs[0].tolist()\n",
        "    token_ids = token_ids[0].tolist()\n",
        "\n",
        "    tokens = [tokenizer.ids_to_tokens[i] for i in token_ids]\n",
        "\n",
        "    results.append({\n",
        "        'sentence': sentence,\n",
        "        'label': label,\n",
        "        'top_tokens': tokens,\n",
        "        'top_probs': probs,\n",
        "        'correct@1': tokens[0] == label,\n",
        "        'attn': attn\n",
        "    })\n",
        "\n",
        "print(\"correct@1: %.3f\" % (\n",
        "    len([r for r in results if r['correct@1']]) / len(results)\n",
        "))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 240/305 [00:35<00:09,  6.77it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyouc5yHfayf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "\n",
        "correct = [r for r in results if r['correct@1']]\n",
        "wrong = [r for r in results if not r['correct@1']]\n",
        "\n",
        "def show(idx=0, attn_layer=0, is_correct=True):\n",
        "    result = correct[idx] if is_correct else wrong[idx]\n",
        "\n",
        "    # --- format the result into a string\n",
        "    top_str = '\\n\\t'.join([\n",
        "        ('\\t%s\\t(%.4f)' % (tokens, probs)) \n",
        "        for tokens, probs in zip(result['top_tokens'], result['top_probs'])\n",
        "    ])\n",
        "    print(\"%s\\n\\tlabel:\\t%s\\n\\n\\ttop:%s\" % (\n",
        "        result['sentence'], \n",
        "        result['label'], \n",
        "        top_str\n",
        "    ))\n",
        "\n",
        "    # --- visualize attention\n",
        "    print(\"Attention weights (12 heads) from layer %d:\" % attn_layer)\n",
        "    fig, axs = plt.subplots(3, 4, figsize=(18, 12))\n",
        "\n",
        "    toks = ['[CLS]'] + tokenizer.tokenize(result['sentence']) + ['[SEP]']\n",
        "    for i, ax in enumerate(axs.reshape(-1)):\n",
        "        ax.matshow(result['attn'][attn_layer][0][i].data.cpu().numpy(), cmap='gray')\n",
        "\n",
        "        ax.set_xticks(range(len(toks)))\n",
        "        ax.set_xticklabels(toks, rotation=90, fontsize=15)\n",
        "        ax.set_yticks(range(len(toks)))\n",
        "        ax.set_yticklabels(toks, fontsize=15)\n",
        "    plt.tight_layout()\n",
        "    \n",
        "interactive(\n",
        "    show, \n",
        "    idx=(0, min(len(correct), len(wrong))-1), \n",
        "    attn_layer=range(12), \n",
        "    is_correct=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoKj_HmJfayj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}